{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Flatten,Conv1D,MaxPooling1D,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from numpy import array\n",
    "from numpy import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip = zipfile.ZipFile('combined_df_1030.zip')\n",
    "#zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip = zipfile.ZipFile('combined_df_2030.zip')\n",
    "#zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip = zipfile.ZipFile('combined_df_3030.zip')\n",
    "#zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nblocks = [1030, 2030, 3030]\\n#blocks = [1030, 2030, 3030, 4030, 5030, 6030, 7030]\\n\\ndfss = []\\nfor block in blocks:\\n    print(block)\\n    dfss.append(pd.read_csv('combined_df_'+str(block)+'.csv'))\\n    \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "blocks = [1030, 2030, 3030]\n",
    "#blocks = [1030, 2030, 3030, 4030, 5030, 6030, 7030]\n",
    "\n",
    "dfss = []\n",
    "for block in blocks:\n",
    "    print(block)\n",
    "    dfss.append(pd.read_csv('combined_df_'+str(block)+'.csv'))\n",
    "df = pd.concat(dfss) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for single file training, 2 for blockwise training, 3 for full-blisk training\n",
      "1\n",
      "Input block number and angle\n",
      "1030\n",
      "0\n",
      "(21571, 69)\n"
     ]
    }
   ],
   "source": [
    "print('Enter 1 for single file training, 2 for blockwise training, 3 for full-blisk training')\n",
    "\n",
    "def single():\n",
    "    dir_final_save  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Combined_Data/'\n",
    "    print('Input block number and angle')\n",
    "    block = input()\n",
    "    angle = input()\n",
    "    df = pd.read_excel(str(dir_final_save)+'finaldf_forward_with_compensation'+str(block)+'__'+str(int(angle))+'.xlsx')\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def block():\n",
    "    dir_block_save  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Combined_Data/Blockwise/'\n",
    "    print('Input block number')\n",
    "    block = input()\n",
    "    df = pd.read_csv(str(dir_block_save)+str(block)+'.csv', mode='a', chunksize='10000',index=False)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "    \n",
    "def blisk():\n",
    "    dir_blisk_save  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Combined_Data/Blisk/'\n",
    "    df = pd.read_csv(str(dir_blisk_save)+'cleaned_full_blisk'+'.csv', mode='a', chunksize='10000',index=False)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "    \n",
    "switch = { \n",
    "           1 : single,\n",
    "           2 : block,\n",
    "           3 : blisk,\n",
    "          }\n",
    "\n",
    "df = switch[int(input())]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Leading angle', 'Side tilt angle', 'Surface Contact point X',\n",
       "       'Surface contact point Y', 'Surface contact point z',\n",
       "       'Surface Orietation X', 'Surface Orietation Y', 'Surface Orietation Z',\n",
       "       'Tool Tip Point X', 'Tool Tip Point Y', 'Tool Tip Point Z',\n",
       "       'Tool Orientation X', 'Tool Orientation Y', 'Tool Orientation Z',\n",
       "       'Closes Point Distance (Surface Contact Point - Acquired TCP 1030 blade0)',\n",
       "       'time', 'MachineX', 'MachineY', 'MachineZ', 'MachineA', 'MachineC',\n",
       "       'LoadSpindle', 'TransfX', 'TransfY', 'TransfZ', 'TransfI', 'TransfJ',\n",
       "       'TransfK', 'executionDuration', 'previousExecutionDuration',\n",
       "       'relativeTimetoPreviousCall program number', 'timeStamp', 'Tool Length',\n",
       "       'Tool Radius', 'G54-X', 'G54-Y', 'G54-Z', 'G54-A', 'G54-C',\n",
       "       'ProgNumber', 'Blade', 'Fx_mean', 'Fy_mean', 'Fz_mean', 'Mz_mean',\n",
       "       'Fc_mean', 'Fa_mean', 'FcN_mean', 'Fres_mean', 'Fx_sigma', 'Fy_sigma',\n",
       "       'Fz_sigma', 'Mz_sigma', 'Fc_sigma', 'Fa_sigma', 'FcN_sigma',\n",
       "       'Fres_sigma', 'Fx_max', 'Fy_max', 'Fz_max', 'Mz_max', 'Fc_max',\n",
       "       'Fa_max', 'FcN_max', 'Fres_max', 'compensation_x', 'compensation_y',\n",
       "       'compensation_z', 'tcp_error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X = df[['Leading angle','Side tilt angle','Tool Tip Point X',\n",
    "           'Tool Tip Point Y', 'Tool Tip Point Z', 'Tool Orientation X',\n",
    "           'Tool Orientation Y', 'Tool Orientation Z',]].copy(deep=True).to_numpy()\n",
    "    y = df[['MachineX', 'MachineY', 'MachineZ', 'MachineA', 'MachineC']].copy(deep=True).to_numpy()\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=n_inputs, kernel_initializer='he_uniform', activation='sigmoid'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    " \n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=3, n_repeats=1, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X[0:100]):\n",
    "        print('Train index:', train_ix.shape,'Test_index',test_ix.shape)\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        \n",
    "        # fit model\n",
    "        print('model fit')\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "        # evaluate model on test set\n",
    "        print('model evaluate')\n",
    "        mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "        # store result\n",
    "        print('mae:',mae)\n",
    "        results.append(mae)\n",
    "    return results\n",
    " \n",
    "# load dataset\n",
    "X, y = get_dataset()\n",
    "# evaluate model\n",
    "results = evaluate_model(X[:,:], y[:,:])\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(18.504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_regression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=3, random_state=2)\n",
    "    return X, y\n",
    " \n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, kernel_initializer='he_uniform'))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    " \n",
    "# load dataset\n",
    "X, y = get_dataset()\n",
    "n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "# get model\n",
    "model = get_model(n_inputs, n_outputs)\n",
    "# fit the model on all data\n",
    "model.fit(X, y, verbose=0, epochs=100)\n",
    "# make a prediction for new data\n",
    "row = [-0.99859353,2.19284309,-0.42632569,-0.21043258,-1.13655612,-0.55671602,-0.63169045,-0.87625098,-0.99445578,-0.3677487]\n",
    "newX = asarray([row])\n",
    "yhat = model.predict(newX)\n",
    "print('Predicted: %s' % yhat[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyAstronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.0.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from keras-tuner) (1.19.5)\n",
      "Requirement already satisfied: scipy in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from keras-tuner) (1.7.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from keras-tuner) (21.0)\n",
      "Requirement already satisfied: ipython in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from keras-tuner) (7.22.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from keras-tuner) (2.26.0)\n",
      "Requirement already satisfied: tensorboard in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from keras-tuner) (2.5.0)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt-legacy-1.0.3.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: colorama in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: traitlets>=4.2 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (5.0.5)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (0.17.2)\n",
      "Requirement already satisfied: backcall in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: decorator in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (5.0.9)\n",
      "Requirement already satisfied: pygments in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (2.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (3.0.17)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from ipython->keras-tuner) (52.0.0.post20210125)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from requests->keras-tuner) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from requests->keras-tuner) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from requests->keras-tuner) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from requests->keras-tuner) (1.26.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.5)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (1.34.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (1.34.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (3.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.4)\n",
      "Requirement already satisfied: six in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from absl-py>=0.4->tensorboard->keras-tuner) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda_installer\\envs\\ictm\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
      "Building wheels for collected packages: kt-legacy\n",
      "  Building wheel for kt-legacy (setup.py): started\n",
      "  Building wheel for kt-legacy (setup.py): finished with status 'done'\n",
      "  Created wheel for kt-legacy: filename=kt_legacy-1.0.3-py3-none-any.whl size=9562 sha256=036f26188624ff7af08946f306cc0f1e619081c68fe65b8cdd06b968731df154\n",
      "  Stored in directory: c:\\users\\rohan\\appdata\\local\\pip\\cache\\wheels\\a8\\67\\9d\\0dece28e14096b9ef4403317a090c3bfe1dc6a4d0a1287360a\n",
      "Successfully built kt-legacy\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.0.3 kt-legacy-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
