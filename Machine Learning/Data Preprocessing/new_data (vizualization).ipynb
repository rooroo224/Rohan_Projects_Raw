{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Rohan Krishna Balaji  <br>\n",
    "Course : Simulation Science <br>\n",
    "Date  : 25.06.2021  <br>\n",
    "Project : ICTM Analysis, Master's Thesis at Fraunhofer IPT <br>\n",
    "Email :  rohan.balaji@rwth-aachen.de <br>\n",
    "Verion : 1.01 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "To obtain the complete data set which includes feature from both planning data used in CAM planning and machining data obtained from Parquet fles First is to convert the machining data in machine coordinate system to tool tip data in work space coordinate system through 'Forward Kinematic Transformations' on compensated data. Then each tool tip data is clusterd to the correspoding acqired data points. Then the obtained clasters are averged to generate combined dataset with both planning and machining data.\n",
    "The dataset is filtered to remove the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and general settings\n",
    "import transformation\n",
    "import compensation\n",
    "import data_imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the result obtained during the study\n",
    "def subplotter(low,high,X,Y,Z,X_inv,Y_inv,Z_inv):\n",
    "    \n",
    "    range = np.arange(low,high)\n",
    "    fig,axs = plt.subplots(3,figsize=(10,15))\n",
    "\n",
    "    axs[0].plot(range,X[range],label = 'X old', color='blue')\n",
    "    axs[0].plot(range,X_inv[range],label = 'X new', color='red')\n",
    "    axs[0].legend() \n",
    "    axs[0].set_xlabel('row index (dimension less)')\n",
    "    axs[0].set_ylabel('X in mm')\n",
    "    #axs[0].set_title('X data comparison')   \n",
    "    \n",
    "    axs[1].plot(range,Y[range], label = 'Y old', color='blue')\n",
    "    axs[1].plot(range,Y_inv[range], label = 'Y new', color='red') \n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel('row index (dimension less)')\n",
    "    axs[1].set_ylabel('Y in mm')\n",
    "   # axs[1].set_title('Y data comparison')   \n",
    "    \n",
    "\n",
    "    axs[2].plot(range,Z[range], label = 'Z old', color='blue')\n",
    "    axs[2].plot(range,Z_inv[range] , label = 'Z new', color='red')\n",
    "    axs[2].legend()\n",
    "    axs[2].set_xlabel('row index (dimension less)')\n",
    "    axs[2].set_ylabel('Z in mm')\n",
    "    #axs[2].set_title('Z data comparison')   \n",
    "    \n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "\n",
    "def subplotter_2(x1,y1,z1,a1,c1,x2,y2,z2,a2,c2,i,block,angle):\n",
    " \n",
    "    filename = f'{i}.png'\n",
    "    \n",
    "    fig,axs = plt.subplots(5,2,figsize=(10,15))\n",
    "\n",
    "    axs[0][0].plot(x1,label = 'x acquired old'+'--'+str(block)+'--'+str(angle), color='blue')\n",
    "    axs[0][0].legend() \n",
    "    axs[0][0].set_xlabel('row index (dimension less)')\n",
    "    axs[0][0].set_ylabel('x in mm')   \n",
    "    \n",
    "    axs[1][0].plot(y1, label = 'y acquired old'+'--'+str(block)+'--'+str(angle), color='blue')\n",
    "    axs[1][0].legend()\n",
    "    axs[1][0].set_xlabel('row index (dimension less)')\n",
    "    axs[1][0].set_ylabel('y in mm')  \n",
    "\n",
    "    axs[2][0].plot(z1, label = 'z acquired old'+'--'+str(block)+'--'+str(angle), color='blue')\n",
    "    axs[2][0].legend()\n",
    "    axs[2][0].set_xlabel('row index (dimension less)')\n",
    "    axs[2][0].set_ylabel('z in mm')\n",
    "    \n",
    "    axs[3][0].plot(a1, label = 'a acquired old'+'--'+str(block)+'--'+str(angle), color='blue')\n",
    "    axs[3][0].legend()\n",
    "    axs[3][0].set_xlabel('row index (dimension less)')\n",
    "    axs[3][0].set_ylabel('a in mm')\n",
    "    \n",
    "    axs[4][0].plot(c1, label = 'c acquired old'+'--'+str(block)+'--'+str(angle), color='blue')\n",
    "    axs[4][0].legend()\n",
    "    axs[4][0].set_xlabel('row index (dimension less)')\n",
    "    axs[4][0].set_ylabel('c in mm')\n",
    "    \n",
    "    axs[0][1].plot(x2,label = 'x acquired new'+'--'+str(block)+'--'+str(angle), color='red')\n",
    "    axs[0][1].legend() \n",
    "    axs[0][1].set_xlabel('row index (dimension less)')\n",
    "    axs[0][1].set_ylabel('x in mm')   \n",
    "    \n",
    "    axs[1][1].plot(y2, label = 'y acquired new'+'--'+str(block)+'--'+str(angle), color='red')\n",
    "    axs[1][1].legend()\n",
    "    axs[1][1].set_xlabel('row index (dimension less)')\n",
    "    axs[1][1].set_ylabel('y in mm')  \n",
    "\n",
    "    axs[2][1].plot(z2, label = 'z acquired new'+'--'+str(block)+'--'+str(angle), color='red')\n",
    "    axs[2][1].legend()\n",
    "    axs[2][1].set_xlabel('row index (dimension less)')\n",
    "    axs[2][1].set_ylabel('z in mm')\n",
    "    \n",
    "    axs[3][1].plot(a2, label = 'a acquired new'+'--'+str(block)+'--'+str(angle), color='red')\n",
    "    axs[3][1].legend()\n",
    "    axs[3][1].set_xlabel('row index (dimension less)')\n",
    "    axs[3][1].set_ylabel('a in mm')\n",
    "    \n",
    "    axs[4][1].plot(c2, label = 'c acquired new'+'--'+str(block)+'--'+str(angle), color='red')\n",
    "    axs[4][1].legend()\n",
    "    axs[4][1].set_xlabel('row index (dimension less)')\n",
    "    axs[4][1].set_ylabel('c in mm')\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def subplotter_3(x1,y1,z1,x2,y2,z2,i,block):\n",
    " \n",
    "    filename2 = f'{i}.png'\n",
    "    \n",
    "    fig,axs = plt.subplots(3,2,figsize=(10,15))\n",
    "\n",
    "    axs[0][0].plot(x1,label = 'x planning old'+'--'+str(block), color='blue')\n",
    "    axs[0][0].legend() \n",
    "    axs[0][0].set_xlabel('row index (dimension less)')\n",
    "    axs[0][0].set_ylabel('x in mm')   \n",
    "    \n",
    "    axs[1][0].plot(y1, label = 'y planning old'+'--'+str(block), color='blue')\n",
    "    axs[1][0].legend()\n",
    "    axs[1][0].set_xlabel('row index (dimension less)')\n",
    "    axs[1][0].set_ylabel('y in mm')  \n",
    "\n",
    "    axs[2][0].plot(z1, label = 'z planning old'+'--'+str(block), color='blue')\n",
    "    axs[2][0].legend()\n",
    "    axs[2][0].set_xlabel('row index (dimension less)')\n",
    "    axs[2][0].set_ylabel('z in mm')\n",
    "    \n",
    "    axs[0][1].plot(x2,label = 'x planning new'+'--'+str(block), color='red')\n",
    "    axs[0][1].legend() \n",
    "    axs[0][1].set_xlabel('row index (dimension less)')\n",
    "    axs[0][1].set_ylabel('x in mm')   \n",
    "    \n",
    "    axs[1][1].plot(y2, label = 'y planning new'+'--'+str(block), color='red')\n",
    "    axs[1][1].legend()\n",
    "    axs[1][1].set_xlabel('row index (dimension less)')\n",
    "    axs[1][1].set_ylabel('y in mm')  \n",
    "\n",
    "    axs[2][1].plot(z2, label = 'z planning new'+'--'+str(block), color='red')\n",
    "    axs[2][1].legend()\n",
    "    axs[2][1].set_xlabel('row index (dimension less)')\n",
    "    axs[2][1].set_ylabel('z in mm')\n",
    "\n",
    "    plt.savefig(filename2)\n",
    "    plt.close()\n",
    "    \n",
    "    return filename2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gif_gen(filenames,gifname):    \n",
    "    frame = []\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        frame.append(image)\n",
    "        \n",
    "    imageio.mimsave(gifname+'.gif', frame, format='GIF', duration=1)\n",
    "        \n",
    "    # Remove files\n",
    "    for filename in set(filenames):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030 12\n",
      "1030 72\n",
      "1030 84\n",
      "2030 12\n",
      "2030 72\n",
      "2030 84\n",
      "3030 12\n",
      "3030 72\n",
      "3030 84\n",
      "4030 12\n",
      "4030 72\n",
      "4030 84\n",
      "6030 12\n",
      "6030 72\n",
      "6030 84\n",
      "7030 12\n",
      "7030 72\n",
      "7030 84\n"
     ]
    }
   ],
   "source": [
    "#blocks = [1030, 2030, 3030, 4030, 5030, 6030, 7030]\n",
    "#angles = list(np.linspace(0,348,30))\n",
    "#dir_final_save  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Combined_Data/'\n",
    "\n",
    "#blocks = [1030, 2030, 3030, 4030, 6030, 7030]\n",
    "blocks = [1030]\n",
    "angles = [12,72,84]\n",
    "dir_final_save1  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Manufacturing_Data/'\n",
    "dir_final_save2  = 'D:/rohan/thesis/Projects/Machine_Learning/Data_2021/Parquet/'\n",
    "\n",
    "i = 0 \n",
    "\n",
    "filenames = []\n",
    "for block in blocks:\n",
    "    for angle in angles:\n",
    "        i = i+1\n",
    "        print(block, angle)\n",
    "        \n",
    "        #df_m = pd.read_parquet('ProgNumber-'+str(block)+'--Blade--'+str(int(angle))+'_DownsampledData'+'.parquet')\n",
    "        df_m1 = pd.read_parquet(str(dir_final_save1)+'ProgNumber-'+str(block)+'--Blade--'+str(angle)+'_DownsampledData'+'.parquet')\n",
    "        \n",
    "        x1 = df_m1['MachineX'].copy(deep=True).to_numpy()\n",
    "        y1 = df_m1['MachineY'].copy(deep=True).to_numpy()\n",
    "        z1 = df_m1['MachineZ'].copy(deep=True).to_numpy()\n",
    "        a1 = np.radians(df_m1['MachineA']).copy(deep=True).to_numpy()\n",
    "        c1 = np.radians(df_m1['MachineC']).copy(deep=True).to_numpy()\n",
    "        \n",
    "        df_m2 = pd.read_parquet(str(dir_final_save2)+str(int(angle))+'-'+str(block+3)+'-0'+'.parquet')\n",
    "        df_m2 = df_m2.rename(columns=df_m2.iloc[0])\n",
    "        df_m2 = df_m2.iloc[1: , :]\n",
    "        \n",
    "        x2 = pd.to_numeric(df_m2['DynamicData     McX']).to_numpy()\n",
    "        y2 = pd.to_numeric(df_m2['DynamicData     McY']).to_numpy()\n",
    "        z2 = pd.to_numeric(df_m2['DynamicData     McZ']).to_numpy()\n",
    "        a2 = pd.to_numeric(df_m2['DynamicData     Mc4th']).to_numpy()\n",
    "        c2 = pd.to_numeric(df_m2['DynamicData     Mc5th']).to_numpy()\n",
    "        \n",
    "        #x2 = pd.to_numeric(df_m2['DynamicData     WcX']).to_numpy()\n",
    "        #y2 = pd.to_numeric(df_m2['DynamicData     WcY']).to_numpy()\n",
    "        #z2 = pd.to_numeric(df_m2['DynamicData     WcZ']).to_numpy()\n",
    "        #a2 = pd.to_numeric(df_m2['DynamicData     Wc4th']).to_numpy()\n",
    "        #c2 = pd.to_numeric(df_m2['DynamicData     Wc5th']).to_numpy()\n",
    "        \n",
    "        \n",
    "        filenames.append(subplotter_2(x1,y1,z1,a1,c1,x2,y2,z2,a2,c2,i,block,angle))\n",
    "        \n",
    "\n",
    "gif_gen(filenames,'combined_acquired_mcx_1030...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7030\n"
     ]
    }
   ],
   "source": [
    "#blocks = [1030, 2030, 3030, 4030, 5030, 6030, 7030]\n",
    "#angles = list(np.linspace(0,348,30))\n",
    "#dir_final_save  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Combined_Data/'\n",
    "\n",
    "#blocks = [1030, 2030, 3030, 4030, 6030, 7030]\n",
    "blocks = [7030]\n",
    "angles = [12,72,84]\n",
    "dir_final_save1  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Planning_Data/'\n",
    "dir_final_save2  = 'D:/rohan/thesis/Projects/Machine_Learning/Data_2021/Toolpath/'\n",
    "\n",
    "i = 0 \n",
    "\n",
    "filenames2 = []\n",
    "for block in blocks:\n",
    "    i = i+1\n",
    "    print(block)\n",
    "        \n",
    "    #df_m = pd.read_parquet('ProgNumber-'+str(block)+'--Blade--'+str(int(angle))+'_DownsampledData'+'.parquet')\n",
    "    df_m1 = pd.read_excel(dir_final_save1+'Planning_Data_OP'+str(block)+'.xlsx', engine='openpyxl')\n",
    "    \n",
    "    x1 = df_m1['Tool Tip Point X'].copy(deep=True).to_numpy()\n",
    "    y1 = df_m1['Tool Tip Point Y'].copy(deep=True).to_numpy()\n",
    "    z1 = df_m1['Tool Tip Point Z'].copy(deep=True).to_numpy()\n",
    "        \n",
    "    df_m2 = pd.read_csv(dir_final_save2+'OP'+str(block)+'_TD_and_WD'+'.csv',delimiter= ';')\n",
    "        \n",
    "    x2 = pd.to_numeric(df_m2['X_TTP Q [mm]']).to_numpy()\n",
    "    y2 = pd.to_numeric(df_m2['Y_TTP  [mm]']).to_numpy()\n",
    "    z2 = pd.to_numeric(df_m2['Z_TTP  [mm]']).to_numpy()\n",
    "            \n",
    "    filenames2.append(subplotter_3(x1,y1,z1,x2,y2,z2,i,block))\n",
    "       \n",
    "gif_gen(filenames2,'combined_planning_7030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DynamicData     WcX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda_Installer\\envs\\ictm2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DynamicData     WcX'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-808e866144ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_m1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_final_save1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Planning_Data_OP'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'openpyxl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_m2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DynamicData     WcX'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_m2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DynamicData     WcY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_m2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DynamicData     WcZ'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_Installer\\envs\\ictm2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_Installer\\envs\\ictm2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DynamicData     WcX'"
     ]
    }
   ],
   "source": [
    "block = 7030\n",
    "\n",
    "dir_final_save1  = 'D:/rohan/thesis/Projects/Machine_Learning/Data/Planning_Data/'\n",
    "dir_final_save2  = 'D:/rohan/thesis/Projects/Machine_Learning/Data_2021/Toolpath/'\n",
    "\n",
    "df_m1 = pd.read_excel(dir_final_save1+'Planning_Data_OP'+str(block)+'.xlsx', engine='openpyxl')\n",
    "    \n",
    "x1 = pd.to_numeric(df_m2['DynamicData     WcX']).to_numpy()\n",
    "y1 = pd.to_numeric(df_m2['DynamicData     WcY']).to_numpy()\n",
    "z1 = pd.to_numeric(df_m2['DynamicData     WcZ']).to_numpy()\n",
    "        \n",
    "df_m2 = pd.read_csv(dir_final_save2+'OP'+str(block)+'_TD_and_WD'+'.csv',delimiter= ';')\n",
    "        \n",
    "x2 = pd.to_numeric(df_m2['X_TTP Q [mm]']).to_numpy()\n",
    "y2 = pd.to_numeric(df_m2['Y_TTP  [mm]']).to_numpy()\n",
    "z2 = pd.to_numeric(df_m2['Z_TTP  [mm]']).to_numpy()\n",
    "\n",
    "subplotter(0,20000,x1,y2,z1,x2,y2,z2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "blocks = [1033, 2033, 3033, 4033, 6033, 7033]\n",
    "angles = [12,72,84]\n",
    "dir_final_save  = 'D:/rohan/thesis/Projects/Machine_Learning/Data_2021/Parquet/'\n",
    "\n",
    "i = 0 \n",
    "\n",
    "filenames = []\n",
    "for block in blocks:\n",
    "    for angle in angles:\n",
    "        i = i+1\n",
    "        print(block, angle)\n",
    "        df_m = pd.read_parquet(str(dir_final_save)+str(int(angle))+'-'+str(block)+'-0'+'.parquet')\n",
    "        \n",
    "        df_m = df_m.rename(columns=df_m.iloc[0])\n",
    "        df_m = df_m.iloc[1: , :]\n",
    "        x = pd.to_numeric(df_m['DynamicData     McX']).to_numpy()\n",
    "        y = pd.to_numeric(df_m['DynamicData     McY']).to_numpy()\n",
    "        z = pd.to_numeric(df_m['DynamicData     McZ']).to_numpy()\n",
    "        a = pd.to_numeric(df_m['DynamicData     Mc4th']).to_numpy()\n",
    "        c = pd.to_numeric(df_m['DynamicData     Mc5th']).to_numpy()\n",
    "        \n",
    "    filenames.append(subplotter_2(x,y,z,a,c,i,block,angle))\n",
    "        \n",
    "\n",
    "gif_gen(filenames,'new_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path locations (folder location) for respective files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_parquet('D:/rohan/thesis/Projects/Machine_Learning/Data_2021/Parquet/96-1030-0.parquet')\n",
    "angle = 96\n",
    "df_p = pd.read_csv('D:/rohan/thesis/Projects/Machine_Learning/Data_2021/Toolpath/OP1030.csv',delimiter= ';')\n",
    "\n",
    "df_m = df_m.rename(columns=df_m.iloc[0])\n",
    "df_m = df_m.iloc[1: , :]\n",
    "print(df_m.columns)\n",
    "\n",
    "x = pd.to_numeric(df_m['DynamicData     McX']).to_numpy()\n",
    "y = pd.to_numeric(df_m['DynamicData     McY']).to_numpy()\n",
    "z = pd.to_numeric(df_m['DynamicData     McZ']).to_numpy()\n",
    "a = pd.to_numeric(df_m['DynamicData     Mc4th']).to_numpy()\n",
    "c = pd.to_numeric(df_m['DynamicData     Mc5th']).to_numpy()\n",
    "\n",
    "tool_tip_X = df_p['X_TTP Q [mm]'].to_numpy()\n",
    "tool_tip_Y = df_p['Y_TTP  [mm]'].to_numpy()\n",
    "tool_tip_Z = df_p['Z_TTP  [mm]'].to_numpy()\n",
    "X_inv=tool_tip_X\n",
    "Y_inv=tool_tip_Y\n",
    "Z_inv=tool_tip_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_parquet('D:/rohan/thesis/Projects/Machine_Learning/Data/Manufacturing_Data/ProgNumber-1030--Blade--180_DownsampledData.parquet')\n",
    "angle = 180\n",
    "df_p = pd.read_excel('D:/rohan/thesis/Projects/Machine_Learning/Data/Planning_Data/Planning_Data_OP1030.xlsx', engine='openpyxl') \n",
    "\n",
    "x = df_m['MachineX'].copy(deep=True).to_numpy()\n",
    "y = df_m['MachineY'].copy(deep=True).to_numpy()\n",
    "z = df_m['MachineZ'].copy(deep=True).to_numpy()\n",
    "a = np.radians(df_m['MachineA']).copy(deep=True).to_numpy()\n",
    "c = np.radians(df_m['MachineC']).copy(deep=True).to_numpy()\n",
    "\n",
    "tool_tip_X = df_p['Tool Tip Point X'].to_numpy()\n",
    "tool_tip_Y = df_p['Tool Tip Point Y'].to_numpy()\n",
    "tool_tip_Z = df_p['Tool Tip Point Z'].to_numpy()\n",
    "X_inv=tool_tip_X\n",
    "Y_inv=tool_tip_Y\n",
    "Z_inv=tool_tip_Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(30,45))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(x[1000:-1000], y[1000:-1000], z[1000:-1000], color = 'red',label = 'raw machine Data')\n",
    "#ax.scatter3D(x, y, z, color = 'red',label = 'raw machine Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Transformation:\n",
    "Forward transformation is performed by applying rotational and transitional\n",
    "transformations on the machine points and orientation in the machine coordi-\n",
    "nate system.\n",
    "There are two ways to interpret the transformations. Firstly, by pre-multiplication\n",
    "of all the transformation matrices with respect to base coordinate system (i.e\n",
    "Machine Coordinate System). Second method is the apply post- multiplica-\n",
    "tion this can be understood as applying 'Relative Transformation'.\n",
    "The notation used for machine data points obtained by paraqet fles are\n",
    "x,y,z,a,c in machine coordinate system. The tool tip and orientations obtained\n",
    "in workpiece coordinate system X,Y,Z,I,J,K. This is implemented in transformation.py script.\n",
    "\n",
    "<img src=\"images/transformation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import root\n",
    "\n",
    "size1 = x.shape[0]\n",
    "#angle = 96\n",
    "\n",
    "OprOm_x = 0\n",
    "OprOm_y = 0\n",
    "OprOm_z = -510.483#+167.85\n",
    "\n",
    "OtOa_x = 0.0011\n",
    "OtOa_y =-0.0093  \n",
    "OtOa_z =-600.2241\n",
    "\n",
    "OtOc_x = 0.0304\n",
    "OtOc_y = -0.0028\n",
    "OtOc_z = -79.7629\n",
    "\n",
    "l = 0\n",
    "tl = 226.6649\n",
    "\n",
    "IT_x=0\n",
    "IT_y=0\n",
    "IT_z=1\n",
    "\n",
    "T_x = 0\n",
    "T_y = 0\n",
    "T_z = tl-l\n",
    "T_CentertoTip = l\n",
    "\n",
    "OprOm_x = 0\n",
    "OprOm_y = 0\n",
    "OprOm_z = -510.4830#+167.85\n",
    "\n",
    "# Zeropoint to A Table\n",
    "l = 0\n",
    "tl = 226.6649\n",
    "OtOa_x =0.008 #19700\n",
    "OtOa_y =-0.0004 #19701\n",
    "OtOa_z =-600.2464 #19702\n",
    "# C excentration from Table\n",
    "OtOc_x = -0.0185 #19703\n",
    "OtOc_y = -0.0035 #19704\n",
    "OtOc_z = -79.7629 #19705\n",
    "# Tool dimensions\n",
    "T_x = 0\n",
    "T_y = 0\n",
    "T_z = tl#-l)\n",
    "T_CentertoTip = l\n",
    "    \n",
    "\n",
    "size = size1\n",
    "ones = np.ones((size,))\n",
    "zeros = np.zeros((size,))\n",
    "\n",
    "init_C = np.array([[np.cos(np.radians(-angle))*ones,  -np.sin(np.radians(-angle))*ones, zeros, zeros],\n",
    "                    [np.sin(np.radians(-angle))*ones,  np.cos(np.radians(-angle))*ones, zeros, zeros],\n",
    "                    [zeros,                            zeros,                           ones,  zeros],\n",
    "                    [zeros,                             zeros,                          zeros, ones]])\n",
    "\n",
    "        \n",
    "matrix_translationA = np.array([[ones,  zeros, zeros,  np.ones((size,))*(-OtOa_x-T_x)],\n",
    "                                [zeros, ones,  zeros,  np.ones((size,))*(-OtOa_y-T_y)],\n",
    "                                [zeros, zeros, ones,   np.ones((size,))*(-OtOa_z-T_z)],\n",
    "                                [zeros, zeros, zeros,  ones  ]])\n",
    "        \n",
    "matrix_rotationA = np.array([[ones,   zeros,       zeros,      zeros],\n",
    "                            [zeros,   np.cos(a),  -np.sin(a),  zeros],\n",
    "                            [zeros,   np.sin(a),   np.cos(a),  zeros],\n",
    "                            [zeros,   zeros,       zeros       ,ones ]],)\n",
    "         \n",
    "matrix_translationC = np.array([[ones,  zeros, zeros,  -np.ones((size,))*OtOc_x],\n",
    "                                [zeros, ones,  zeros,  -np.ones((size,))*OtOc_y],\n",
    "                                [zeros, zeros, ones,   -np.ones((size,))*OtOc_z],\n",
    "                                [zeros, zeros, zeros,   ones  ]])\n",
    "\n",
    "matrix_rotationC = np.array([[np.cos(c), -np.sin(c), zeros, zeros],\n",
    "                             [np.sin(c),   np.cos(c), zeros, zeros],\n",
    "                             [zeros,       zeros,     ones,  zeros],\n",
    "                             [zeros,       zeros,     zeros, ones]])\n",
    "        \n",
    "matrix_back_translation = np.array([[ones,  zeros, zeros,   np.ones((size,))*(-OprOm_x +OtOa_x + OtOc_x)  ],\n",
    "                                    [zeros, ones,  zeros,   np.ones((size,))*(-OprOm_y + OtOa_y + OtOc_y) ],\n",
    "                                    [zeros, zeros, ones,    np.ones((size,))*(-OprOm_z + OtOa_z + OtOc_z) ],\n",
    "                                    [zeros, zeros, zeros,   ones                                         ]])\n",
    "        \n",
    "\n",
    "initial_tool_position = np.array([[ones*[IT_x]],\n",
    "                                  [ones*[IT_y]],\n",
    "                                  [ones*[IT_z]],\n",
    "                                  [ones*[0]]])\n",
    "      \n",
    "machine_points_xyz   = np.array([[x],\n",
    "                                 [y],\n",
    "                                 [z],\n",
    "                                 [ones]])\n",
    "        \n",
    "\n",
    "\n",
    "        #Forward transformation <-- Back Translation * Rotation on C axis * Translation in C axis * Rotation on A axis * Translation in A\n",
    "\n",
    "forward_transformation = np.transpose(init_C, (2,0,1)) @ \\\n",
    "                                      np.transpose(matrix_back_translation,(2,0,1))@ \\\n",
    "                                      np.transpose(matrix_rotationC, (2,0,1)) @ \\\n",
    "                                      np.transpose(matrix_translationC, (2,0,1))@ \\\n",
    "                                      np.transpose(matrix_rotationA, (2,0,1))@ \\\n",
    "                                      np.transpose(matrix_translationA, (2,0,1))\n",
    "        \n",
    "tool_position_workpiece_CS = forward_transformation @ np.transpose(machine_points_xyz,(2,0,1))\n",
    "tool_position_workpiece_CS = np.transpose(tool_position_workpiece_CS,(1,2,0))\n",
    "        \n",
    "tool_orientation_workpiece_CS = forward_transformation @ np.transpose(initial_tool_position,(2,0,1))\n",
    "tool_orientation_workpiece_CS = np.transpose(tool_orientation_workpiece_CS,(1,2,0))\n",
    "\n",
    "X = tool_position_workpiece_CS[0,0,:]\n",
    "Y = tool_position_workpiece_CS[1,0,:]\n",
    "Z = tool_position_workpiece_CS[2,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplotter(0,10000,X,Y,Z,X_inv,Y_inv,Z_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import math\n",
    "import re\n",
    "# Vocabulary\n",
    "\n",
    "# Opr : Program origin (G54)\n",
    "# Om : Machine origin (unknow point somewhere out of work space)\n",
    "# Ot : Turret origin (liaison with the öachine)\n",
    "# Ob : Rotation center of B\n",
    "# Tcp : Tool center point\n",
    "\n",
    "# Program origin (G54 values)\n",
    "OprOm_x = 0\n",
    "OprOm_y = 0\n",
    "OprOm_z = -510.4830#+167.85\n",
    "# Tool position\n",
    "OmOt_x = x\n",
    "OmOt_y = y\n",
    "OmOt_z = z\n",
    "OmOt_a = a\n",
    "OmOt_c = c\n",
    "# Zeropoint to A Table\n",
    "l = 0\n",
    "tl = 226.6649\n",
    "OtOa_x =0.008 #19700\n",
    "OtOa_y =-0.0004 #19701\n",
    "OtOa_z =-600.2464 #19702\n",
    "# C excentration from Table\n",
    "OtOc_x = -0.0185 #19703\n",
    "OtOc_y = -0.0035 #19704\n",
    "OtOc_z = -79.7629 #19705\n",
    "# Tool dimensions\n",
    "T_x = 0\n",
    "T_y = 0\n",
    "T_z = tl#-l)\n",
    "T_CentertoTip = l\n",
    "# Translation Werkzeuglänge und Base Tool -> Reihenfolgen der Translationen und Rotationen zu hinterfragen\n",
    "nx = OmOt_x-OtOa_x-T_x\n",
    "ny = OmOt_y-OtOa_y-T_y\n",
    "nz = OmOt_z-OtOa_z-T_z\n",
    "na = OmOt_a\n",
    "nc = OmOt_c\n",
    "#ROT um X --> A-Achse\n",
    "OmOt_x = nx\n",
    "OmOt_y = np.cos(na)*ny - np.sin(na)*nz\n",
    "OmOt_z = np.sin(na)*ny + np.cos(na)*nz\n",
    "#JO Translation\n",
    "nx = OmOt_x - OtOc_x\n",
    "ny = OmOt_y - OtOc_y\n",
    "nz = OmOt_z - OtOc_z\n",
    "# rot z -> C-Achse\n",
    "OmOt_x = np.cos(nc)*nx - np.sin(nc)*ny\n",
    "OmOt_y = np.sin(nc)*nx + np.cos(nc)*ny\n",
    "OmOt_z = nz\n",
    "#G54 Transformationen und Werkzeuglänge zurück transformieren -> Ab hier wahrscheinlich kein fehler mehr! <<-- DOCH!!\n",
    "X = OmOt_x - OprOm_x + OtOa_x +OtOc_x\n",
    "Y = OmOt_y - OprOm_y + OtOa_y + OtOc_y\n",
    "Z = OmOt_z - OprOm_z + OtOa_z + OtOc_z\n",
    "IT_x=0\n",
    "IT_y=0\n",
    "IT_z=1\n",
    "#ROT um X --> A-Achse\n",
    "nIT_x = IT_x\n",
    "nIT_y = np.cos(a)*IT_y - np.sin(a)*IT_z\n",
    "nIT_z = np.sin(a)*IT_y + np.cos(a)*IT_z\n",
    "IT_x=nIT_x\n",
    "IT_y=nIT_y\n",
    "IT_z=nIT_z\n",
    "# rot z -> C-Achse\n",
    "nIT_x = np.cos(c)*IT_x - np.sin(c)*IT_y\n",
    "nIT_y = np.sin(c)*IT_x + np.cos(c)*IT_y\n",
    "nIT_z = IT_z\n",
    "I=nIT_x\n",
    "J=nIT_y\n",
    "K=nIT_z\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# example\n",
    "n = 15000\n",
    "distance1 = (((df_p['Tool Tip Point X']-X[n])**2+(df_p['Tool Tip Point Y']-Y[n])**2+(df_p['Tool Tip Point Z']-Z[n])**2)**(1/2))\n",
    "distance1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.to_numeric(df_m['DynamicData     WcX']).to_numpy()\n",
    "Y = pd.to_numeric(df_m['DynamicData     WcY']).to_numpy()\n",
    "Z = pd.to_numeric(df_m['DynamicData     WcZ']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.to_numeric(df_m['DynamicData     WcX']).to_numpy()\n",
    "Y = pd.to_numeric(df_m['DynamicData     WcY']).to_numpy()\n",
    "Z = pd.to_numeric(df_m['DynamicData     WcZ']).to_numpy()\n",
    "angle = 96\n",
    "# 48 , 32.5         #0 , 15.5\n",
    "size = X.shape[0]\n",
    "ones = np.ones((size,))\n",
    "zeros = np.zeros((size,))\n",
    "init_C = np.array([[np.cos(np.radians(-angle))*ones,  -np.sin(np.radians(-angle))*ones, zeros, zeros],\n",
    "                    [np.sin(np.radians(-angle))*ones,  np.cos(np.radians(-angle))*ones, zeros, zeros],\n",
    "                    [zeros,                            zeros,                           ones,  zeros],\n",
    "                    [zeros,                             zeros,                          zeros, ones]])\n",
    "\n",
    "machine_points_xyz   = np.array([[X],\n",
    "                                 [Y],\n",
    "                                 [Z],\n",
    "                                 [ones]])\n",
    "        \n",
    "\n",
    "\n",
    "        #Forward transformation <-- Back Translation * Rotation on C axis * Translation in C axis * Rotation on A axis * Translation in A\n",
    "\n",
    "forward_transformation = np.transpose(init_C, (2,0,1))\n",
    "        \n",
    "tool_position_workpiece_CS = forward_transformation @ np.transpose(machine_points_xyz,(2,0,1))\n",
    "tool_position_workpiece_CS = np.transpose(tool_position_workpiece_CS,(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplotter(0,df_m.shape[0],X,Y,Z,X_inv,Y_inv,Z_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subplotter(1000,28900,X,Y,Z,X_inv,Y_inv,Z_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subplotter(20000,21000,X,Y,Z,X_inv,Y_inv,Z_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "range1 = np.arange(1000,34900)\n",
    "X = X[range1]\n",
    "Y = Y[range1]\n",
    "Z = Z[range1]\n",
    "\n",
    "tool_tip_X = tool_tip_X[range1]\n",
    "tool_tip_Y = tool_tip_Y[range1]\n",
    "tool_tip_Z = tool_tip_Z[range1]\n",
    " \n",
    "X_inv = tool_tip_X\n",
    "Y_inv = tool_tip_Y\n",
    "Z_inv = tool_tip_Z\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the closest points\n",
    "Here the distances are calculated, for each aquired data point, forward transformation was performed above, and now for each of those poits the disace for all planning points are calculated. Partition the data into 5 chuncks and find the closest distance points in those chucks, if we use full set at once, we may match up with far way points, which were causing lots of outliers.the position closest the iterator is considered, since the far away values are thus avoided from matching. store both position and the value in two separate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the distances are calculated, for each aquired data point, forward transformation was performed above,\n",
    "# and now for each of those poits the disace for all planning points are calculated.\n",
    "lst1 = []\n",
    "lst2 = []\n",
    "\n",
    "dist  = np.zeros(len(tool_tip_X))\n",
    "print('Enter the tolerance number value, example 3 mm')\n",
    "#tol = input()\n",
    "tol = 3\n",
    "count = 0 \n",
    "k = 5\n",
    "\n",
    "for i in np.arange(len(X)):   # 47917\n",
    "    \n",
    "    dist = (((tool_tip_X-X[i])**2+(tool_tip_Y-Y[i])**2+(tool_tip_Z-Z[i])**2)**(1/2))\n",
    "    \n",
    "    # partition the data into 5 chuncks and find the closest distance points in those chucks, if we use full set at once, \n",
    "    # we may match up with far way points, which were causing lots of outliers\n",
    "    \n",
    "    pos = np.argpartition(dist, k)\n",
    "    pos = pos[:k]\n",
    "    min_val = dist[pos]\n",
    "    #print(pos,min_val)\n",
    "    \n",
    "    # the position closest the iterator is considered, since the far away values are thus avoided from matching\n",
    "    pos = pos[np.argmin(abs(pos - i))]\n",
    "    min_val = dist[pos]\n",
    "    \n",
    "    #print(i,pos,min_val)\n",
    "    # store both position and the value in two separate lists\n",
    "    if(abs(min_val<=float(tol))): \n",
    "        lst1.append(pos)\n",
    "        lst2.append(min_val)\n",
    "        count = count+1\n",
    "        print(i,pos,min_val,count)\n",
    "    else:\n",
    "        lst1.append(np.nan)\n",
    "        lst2.append(np.nan)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(lst1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing all the unique clusers and number of points in it (Just for understanding)\n",
    "(unique,count) = np.unique(lst1, return_counts=True)\n",
    "\n",
    "df_freq = pd.DataFrame({'Unique Cluster Points':np.array(unique),'Count':np.array(count)})\n",
    "df_freq = df_freq.dropna()\n",
    "df_freq.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cluster = pd.DataFrame({'cluster index in planning data':np.array(lst1),'distance error':np.array(lst2)})\n",
    "#df_cluster = df_cluster.dropna()\n",
    "df_cluster.iloc[22000:22100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering:\n",
    "For a given planning point, there are none or multiple matching acquried points, those are found in this section. For each planning datapoint, see whih index match with the stored index for minimum distance. Those can be considered as the cluster points and the corresponding distance. \n",
    "\n",
    "<img src=\"images/cluster.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering: for a given planning point, there are none or multiple matching acquried points, those are found in this section of code \n",
    "lst3 = []\n",
    "tcp_val = []\n",
    "# For each planning datapoint, see whih index match with the stored index for minimum distance.\n",
    "# Those can be considered as the cluster points and the corresponding distance\n",
    "for i in np.arange(len(tool_tip_Y)):     # each planning point\n",
    "    \n",
    "    matching = np.where(np.array(lst1)==i)    # see what all machine points matches\n",
    "    tcp_val.append([lst2[index] for index in matching[0]])          # get the same minmum tcp error distance \n",
    "    lst3.append(matching[0])\n",
    "    print(i,matching[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for plotting\n",
    "pltlst = []\n",
    "for i in np.arange(len(tool_tip_X)):\n",
    "    if (len(lst3[i]) != 0):\n",
    "        pltlst.append(i)\n",
    "        #print(i,lst3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show clusters\n",
    "xdata, ydata, zdata = np.zeros(len(pltlst),),np.zeros(len(pltlst),),np.zeros(len(pltlst),)\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_zlim3d([0,30])\n",
    "ax.set_xlabel('$X$ in mm', fontsize=20)\n",
    "ax.set_ylabel('$Y$ in mm', fontsize=20)\n",
    "ax.set_zlabel('$Z$ in mm', fontsize=20)\n",
    "\n",
    "for i in np.arange(len(pltlst)):\n",
    "    xdata[i] = tool_tip_X[pltlst[i]]\n",
    "    ydata[i] = tool_tip_Y[pltlst[i]]\n",
    "    zdata[i] = tool_tip_Z[pltlst[i]]\n",
    "\n",
    "ax.scatter3D(xdata, ydata, zdata, color = 'red',label = 'Planning Data')\n",
    "ax.legend()\n",
    "\n",
    "xdata2, ydata2, zdata2 = np.zeros(len(pltlst),),np.zeros(len(pltlst),),np.zeros(len(pltlst),)\n",
    "\n",
    "for i in np.arange(len(pltlst)):\n",
    "    xdata2[i] = np.average(X[tuple([lst3[pltlst[i]]])])\n",
    "    ydata2[i] = np.average(Y[tuple([lst3[pltlst[i]]])])\n",
    "    zdata2[i] = np.average(Z[tuple([lst3[pltlst[i]]])])\n",
    "\n",
    "ax.scatter3D(xdata2, ydata2, zdata2, color = 'blue',label = 'Machine Data Avg')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subplotter(0,xdata.shape[0],xdata2,ydata2,zdata2,xdata,ydata,zdata)\n",
    "subplotter(0,19000,xdata2,ydata2,zdata2,xdata,ydata,zdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = -10\n",
    "xdata, ydata, zdata = np.zeros(len(lst3[pltlst[num]]),),np.zeros(len(lst3[pltlst[num]]),),np.zeros(len(lst3[pltlst[num]]),)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.scatter3D(tool_tip_X[pltlst[num]],tool_tip_Y[pltlst[num]] , tool_tip_Z[pltlst[num]],label='Plannig Data Point')\n",
    "\n",
    "for i in np.arange(len(lst3[pltlst[num]])):\n",
    "    xdata[i] = X[lst3[pltlst[num]]][i]\n",
    "    ydata[i] = Y[lst3[pltlst[num]]][i]\n",
    "    zdata[i] = Z[lst3[pltlst[num]]][i]\n",
    "    \n",
    "ax.scatter3D(xdata, ydata, zdata, label = 'Clustered Acquired Data Points')\n",
    "ax.set_xlabel('X in mm', fontsize=10)\n",
    "ax.set_ylabel('Y in mm', fontsize=10)\n",
    "ax.set_zlabel('Z in mm', fontsize=10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for num in np.arange(len(pltlst)):\n",
    "print('Input two numbers between 0 and {} with small difference for plots exaple 10000 then 10010'.format(len(pltlst)))\n",
    "#lim1 = input()\n",
    "#lim2 = input()\n",
    "\n",
    "lim1 = 0\n",
    "lim2 = 1\n",
    "\n",
    "for num in np.arange(len(pltlst[int(lim1):int(lim2)])):\n",
    "    xdata, ydata, zdata = np.zeros(len(lst3[pltlst[num]]),),np.zeros(len(lst3[pltlst[num]]),),np.zeros(len(lst3[pltlst[num]]),)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    print(num)\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    ax.scatter3D(tool_tip_X[pltlst[num]],tool_tip_Y[pltlst[num]] , tool_tip_Z[pltlst[num]], label='Plannig Data Point')\n",
    "\n",
    "    for i in np.arange(len(lst3[pltlst[num]])):\n",
    "        xdata[i] = X[lst3[pltlst[num]]][i]\n",
    "        ydata[i] = Y[lst3[pltlst[num]]][i]\n",
    "        zdata[i] = Z[lst3[pltlst[num]]][i]\n",
    "    \n",
    "    ax.scatter3D(xdata, ydata, zdata, label = 'Clustered Acquired Data Points')\n",
    "    ax.set_xlabel('X in mm', fontsize=10)\n",
    "    ax.set_ylabel('Y in mm', fontsize=10)\n",
    "    ax.set_zlabel('Z in mm', fontsize=10)\n",
    "    plt.legend()\n",
    "    plt.pause(0.1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the clusterd points the acquired points are averaged\n",
    "lst4 = []\n",
    "for i in np.arange(len(lst3)):\n",
    "    lst4.append(df_m.iloc[list(lst3[i])].mean(axis=0))\n",
    "    \n",
    "mean_m = pd.concat(lst4,axis=1).T\n",
    "mean_m.iloc[-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances are averaged\n",
    "tcp_avg = [(lambda x: sum(x)/len(x))(item) if len(item)!=0 else np.nan for item in tcp_val]\n",
    "len(tcp_avg)\n",
    "#tcp_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the final dataframe with plannind data and the corresponding averaged acquired data is obtained \n",
    "final_df = pd.concat([df_p,mean_m, pd.DataFrame({'tcp_error':tcp_avg})], axis=1)\n",
    "final_df = final_df.drop(['Level','Step'],axis=1)\n",
    "final_df = final_df.dropna()\n",
    "print(final_df.shape)\n",
    "final_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['block'] = block\n",
    "final_df['angle'] = angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.shape)\n",
    "final_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.iloc[int(final_df.shape[0]*0.05):-int(final_df.shape[0]*0.05),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.shape)\n",
    "final_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Combined dataset Peaks Elimination:\n",
    "Inspite of the average, there are some high impuse peaks observed in the data (Run the visualiation.ipnby), these must be removed to obtain a flawless, reliable dataset. Using machine data from newly created combined dataset same forward transformation is performed as discribled above. by observing the data, it can be seen that the using just one of the components (in this case Y) all the outlers can be eliminated. Two types of spikes are typicalled observed (check visualizaion by runnung  vizualization.ipnyb) one in positive direction and othes in negetive direction, so for robostness both are considered. At the same time, it is not wise to remove the original expected trajectory of the tool path in begining and the end, so especially for the positive direction they are intentionally not removed. if each peak on a plateu has to be removed its very expensive, so if two neighbous are consicutively classifies as peaks (given by count), it is assumed as plateu and 100 datapoint sare removed. This is a reasonable compromise in accuracy for significant speedup\n",
    "\n",
    "<img src=\"images/peak_eli.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulaization of outliers peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = final_df['MachineX'].copy(deep=True)                 # using machine data from newly created combined dataset\n",
    "y_final = final_df['MachineY'].copy(deep=True)\n",
    "z_final = final_df['MachineZ'].copy(deep=True)\n",
    "a_final = final_df['MachineA'].copy(deep=True)\n",
    "c_final = final_df['MachineC'].copy(deep=True)\n",
    "\n",
    "size1_final = x_final.shape[0]\n",
    "\n",
    "# converting pandas series to numpy array\n",
    "x_final = x_final.to_numpy()\n",
    "y_final = y_final.to_numpy()\n",
    "z_final = z_final.to_numpy()\n",
    "a_final = a_final.to_numpy(dtype =  np.float64)\n",
    "a_final = np.deg2rad(a_final)\n",
    "c_final = c_final.to_numpy(dtype =  np.float64)\n",
    "c_final = np.deg2rad(c_final)\n",
    "\n",
    "tool_tip_X_final = final_df['Tool Tip Point X'].to_numpy()        # using newly created combined dataset\n",
    "tool_tip_Y_final = final_df['Tool Tip Point Y'].to_numpy()\n",
    "tool_tip_Z_final = final_df['Tool Tip Point Z'].to_numpy()\n",
    "    \n",
    "X_inv_final = tool_tip_X_final\n",
    "Y_inv_final = tool_tip_Y_final\n",
    "Z_inv_final = tool_tip_Z_final\n",
    "    \n",
    "#compensation_values\n",
    "compensation_values = compensation_values_df.to_numpy()\n",
    "\n",
    "# Within each cube we have ranges defined in x,y,z for the machine position\n",
    "\n",
    "x_range = np.arange(-200,201,100)\n",
    "y_range = np.arange(-300,301,150)\n",
    "z_range = np.arange(-500,1,50)\n",
    "\n",
    "obj3_final = compensation.Compensation(compensation_values,x_range,y_range,z_range)\n",
    "\n",
    "# Caclculation of compensation error values based on machine positions obtained through inverse transformation\n",
    "deltaX1_final, deltaY1_final, deltaZ1_final,deltaI1_final,deltaJ1_final,deltaK1_final = obj3_final.calculate(x_final,y_final,z_final)  \n",
    "size3_final = x_final.shape[0]\n",
    "conc3_final = np.concatenate((deltaX1_final.reshape(size3_final,1),deltaY1_final.reshape(size3_final,1),deltaZ1_final.reshape(size3_final,1),deltaI1_final.reshape(size3_final,1),deltaJ1_final.reshape(size3_final,1),deltaK1_final.reshape(size3_final,1)),axis=1)\n",
    "\n",
    "# prininting the compensation error values\n",
    "df_obj3_final = pd.DataFrame(conc3_final, columns=['deltaX1 final','deltaY1 final','deltaZ1 final','deltaI1 final','deltaJ1 final','deltaK1 final'])\n",
    "df_obj3_final.head(5)  \n",
    "\n",
    "x_compensated_final = x_final + deltaX1_final*10**-3    # since given compensation is to be converted from microns to mm (10**-6 x 10**3 = 10**-3)\n",
    "y_compensated_final = y_final + deltaY1_final*10**-3\n",
    "z_compensated_final = z_final + deltaZ1_final*10**-3\n",
    "\n",
    "conc4_final = np.concatenate((x_compensated_final.reshape(size3_final,1),y_compensated_final.reshape(size3_final,1),z_compensated_final.reshape(size3_final,1)),axis=1)\n",
    "df_obj4_final = pd.DataFrame(conc4_final, columns=['x_compensated final','y_compensated final','z_compensated final'])\n",
    "\n",
    "obj_final = transformation.Transformation(size1_final,angle)\n",
    "# Forward Transformation fuction:\n",
    "# Input : Machine points in machine coordinate system\n",
    "# Output: returns too tip points and orientation in workpiece coordinate system\n",
    "tool_position_workpiece_CS_final, tool_orientation_workpiece_CS_final = obj_final.forward(x_compensated_final,y_compensated_final,z_compensated_final,a_final,c_final)\n",
    "\n",
    "X_final = tool_position_workpiece_CS_final[0,0,:]\n",
    "Y_final = tool_position_workpiece_CS_final[1,0,:]\n",
    "Z_final = tool_position_workpiece_CS_final[2,0,:]\n",
    "\n",
    "I_final = tool_orientation_workpiece_CS_final[0,0,:]\n",
    "J_final = tool_orientation_workpiece_CS_final[1,0,:]\n",
    "K_final = tool_orientation_workpiece_CS_final[2,0,:]\n",
    "\n",
    "# Verification the correctness of code, i.e on applying reverse transformation on the forward transformation we should get same values\n",
    "machine_points_xyz_final, machine_direction_ac_final = obj_final.backward(X_final,Y_final,Z_final,I_final,J_final,K_final)\n",
    "\n",
    "x_out_final = machine_points_xyz_final[0,0,:]\n",
    "y_out_final = machine_points_xyz_final[1,0,:]\n",
    "z_out_final = machine_points_xyz_final[2,0,:]\n",
    "\n",
    "a_out_final = machine_direction_ac_final[0,0,:]\n",
    "c_out_final = machine_direction_ac_final[1,0,:]\n",
    "\n",
    "conc1_final = np.concatenate((x_final.reshape(size1_final,1),x_out_final.reshape(size1_final,1),y_final.reshape(size1_final,1),y_out_final.reshape(size1_final,1),z_final.reshape(size1_final,1),z_out_final.reshape(size1_final,1),a_final.reshape(size1_final,1),a_out_final.reshape(size1_final,1),c_final.reshape(size1_final,1),c_out_final.reshape(size1_final,1)),axis=1)\n",
    "df_obj1_final = pd.DataFrame(conc1_final, columns=['x final','x_out final','y final','y_out final','z final','z_out final','a final','a_out final','c final','c_out'])\n",
    "\n",
    "conc11_final = np.concatenate((x_final.reshape(size1_final,1),y_final.reshape(size1_final,1),z_final.reshape(size1_final,1),a_final.reshape(size1_final,1),c_final.reshape(size1_final,1),X_final.reshape(size1_final,1),Y_final.reshape(size1_final,1),Z_final.reshape(size1_final,1),I_final.reshape(size1_final,1),J_final.reshape(size1_final,1),K_final.reshape(size1_final,1)),axis=1)\n",
    "dfout11_final = pd.DataFrame(conc11_final, columns=['x final','y final','z final','a final','c final','X final','Y final','Z final','I final','J final','K final'])\n",
    "    \n",
    "subplotter(0,final_df.shape[0],X_final,Y_final,Z_final,X_inv_final,Y_inv_final,Z_inv_final)   # using combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "ax1 = plt.axes(projection='3d')\n",
    "ax1.set_zlim3d([0,30])\n",
    "\n",
    "ax1.set_xlabel('$X$ in mm', fontsize=20)\n",
    "ax1.set_ylabel('$Y$ in mm', fontsize=20)\n",
    "ax1.set_zlabel('$Z$ in mm', fontsize=20)\n",
    "\n",
    "ax1.scatter3D(X_inv_final, Y_inv_final, Z_inv_final, color = 'red',label = 'Planning Data')\n",
    "ax1.legend()\n",
    "\n",
    "ax1.scatter3D(X_final, Y_final, Z_final, color = 'blue',label = 'Machine Data Avg')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_peaks(final_df, compensation_values_df):\n",
    "    x_final = final_df['MachineX'].copy(deep=True)                 # using machine data from newly created combined dataset\n",
    "    y_final = final_df['MachineY'].copy(deep=True)\n",
    "    z_final = final_df['MachineZ'].copy(deep=True)\n",
    "    a_final = final_df['MachineA'].copy(deep=True)\n",
    "    c_final = final_df['MachineC'].copy(deep=True)\n",
    "\n",
    "    size1_final = x_final.shape[0]\n",
    "\n",
    "    # converting pandas series to numpy array\n",
    "    x_final = x_final.to_numpy()\n",
    "    y_final = y_final.to_numpy()\n",
    "    z_final = z_final.to_numpy()\n",
    "    a_final = a_final.to_numpy(dtype = np.float64)\n",
    "    a_final = np.deg2rad(a_final)\n",
    "    c_final = c_final.to_numpy(dtype = np.float64)\n",
    "    c_final = np.deg2rad(c_final)\n",
    "\n",
    "    tool_tip_X_final = final_df['Tool Tip Point X'].to_numpy()        # using newly created combined dataset\n",
    "    tool_tip_Y_final = final_df['Tool Tip Point Y'].to_numpy()\n",
    "    tool_tip_Z_final = final_df['Tool Tip Point Z'].to_numpy()\n",
    "    \n",
    "    X_inv_final = tool_tip_X_final\n",
    "    Y_inv_final = tool_tip_Y_final\n",
    "    Z_inv_final = tool_tip_Z_final\n",
    "    \n",
    "    #compensation_values\n",
    "    compensation_values = compensation_values_df.to_numpy()\n",
    "\n",
    "    # Within each cube we have ranges defined in x,y,z for the machine position\n",
    "\n",
    "    x_range = np.arange(-200,201,100)\n",
    "    y_range = np.arange(-300,301,150)\n",
    "    z_range = np.arange(-500,1,50)\n",
    "\n",
    "    obj3_final = compensation.Compensation(compensation_values,x_range,y_range,z_range)\n",
    "\n",
    "    # Caclculation of compensation error values based on machine positions obtained through inverse transformation\n",
    "    deltaX1_final, deltaY1_final, deltaZ1_final,deltaI1_final,deltaJ1_final,deltaK1_final = obj3_final.calculate(x_final,y_final,z_final)  \n",
    "    size3_final = x_final.shape[0]\n",
    "    conc3_final = np.concatenate((deltaX1_final.reshape(size3_final,1),deltaY1_final.reshape(size3_final,1),deltaZ1_final.reshape(size3_final,1),deltaI1_final.reshape(size3_final,1),deltaJ1_final.reshape(size3_final,1),deltaK1_final.reshape(size3_final,1)),axis=1)\n",
    "\n",
    "    # prininting the compensation error values\n",
    "    df_obj3_final = pd.DataFrame(conc3_final, columns=['deltaX1 final','deltaY1 final','deltaZ1 final','deltaI1 final','deltaJ1 final','deltaK1 final'])\n",
    "    df_obj3_final.head(5)  \n",
    "\n",
    "    x_compensated_final = x_final + deltaX1_final*10**-3    # since given compensation is to be converted from microns to mm (10**-6 x 10**3 = 10**-3)\n",
    "    y_compensated_final = y_final + deltaY1_final*10**-3\n",
    "    z_compensated_final = z_final + deltaZ1_final*10**-3\n",
    "\n",
    "    conc4_final = np.concatenate((x_compensated_final.reshape(size3_final,1),y_compensated_final.reshape(size3_final,1),z_compensated_final.reshape(size3_final,1)),axis=1)\n",
    "    df_obj4_final = pd.DataFrame(conc4_final, columns=['x_compensated final','y_compensated final','z_compensated final'])\n",
    "\n",
    "    obj_final = transformation.Transformation(size1_final,angle)\n",
    "    # Forward Transformation fuction:\n",
    "    # Input : Machine points in machine coordinate system\n",
    "    # Output: returns too tip points and orientation in workpiece coordinate system\n",
    "    tool_position_workpiece_CS_final, tool_orientation_workpiece_CS_final = obj_final.forward(x_compensated_final,y_compensated_final,z_compensated_final,a_final,c_final)\n",
    "\n",
    "    X_final = tool_position_workpiece_CS_final[0,0,:]\n",
    "    Y_final = tool_position_workpiece_CS_final[1,0,:]\n",
    "    Z_final = tool_position_workpiece_CS_final[2,0,:]\n",
    "\n",
    "    I_final = tool_orientation_workpiece_CS_final[0,0,:]\n",
    "    J_final = tool_orientation_workpiece_CS_final[1,0,:]\n",
    "    K_final = tool_orientation_workpiece_CS_final[2,0,:]\n",
    "\n",
    "    # Verification the correctness of code, i.e on applying reverse transformation on the forward transformation we should get same values\n",
    "    machine_points_xyz_final, machine_direction_ac_final = obj_final.backward(X_final,Y_final,Z_final,I_final,J_final,K_final)\n",
    "\n",
    "    x_out_final = machine_points_xyz_final[0,0,:]\n",
    "    y_out_final = machine_points_xyz_final[1,0,:]\n",
    "    z_out_final = machine_points_xyz_final[2,0,:]\n",
    "\n",
    "    a_out_final = machine_direction_ac_final[0,0,:]\n",
    "    c_out_final = machine_direction_ac_final[1,0,:]\n",
    "\n",
    "    conc1_final = np.concatenate((x_final.reshape(size1_final,1),x_out_final.reshape(size1_final,1),y_final.reshape(size1_final,1),y_out_final.reshape(size1_final,1),z_final.reshape(size1_final,1),z_out_final.reshape(size1_final,1),a_final.reshape(size1_final,1),a_out_final.reshape(size1_final,1),c_final.reshape(size1_final,1),c_out_final.reshape(size1_final,1)),axis=1)\n",
    "    df_obj1_final = pd.DataFrame(conc1_final, columns=['x final','x_out final','y final','y_out final','z final','z_out final','a final','a_out final','c final','c_out'])\n",
    "\n",
    "    conc11_final = np.concatenate((x_final.reshape(size1_final,1),y_final.reshape(size1_final,1),z_final.reshape(size1_final,1),a_final.reshape(size1_final,1),c_final.reshape(size1_final,1),X_final.reshape(size1_final,1),Y_final.reshape(size1_final,1),Z_final.reshape(size1_final,1),I_final.reshape(size1_final,1),J_final.reshape(size1_final,1),K_final.reshape(size1_final,1)),axis=1)\n",
    "    dfout11_final = pd.DataFrame(conc11_final, columns=['x final','y final','z final','a final','c final','X final','Y final','Z final','I final','J final','K final'])\n",
    "    \n",
    "    #subplotter(0,final_df.shape[0],X_final,Y_final,Z_final,X_inv_final,Y_inv_final,Z_inv_final)   # using combined dataset\n",
    "    \n",
    "    return Y_final, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak removal: by observing the data,\n",
    "# it can be seen that the using just one of the components (in this case Y) all the outlers can be eliminated. \n",
    "count = 0\n",
    "col = final_df.columns\n",
    "while True:\n",
    "    Y_final, final_df = remove_peaks(final_df,compensation_values_df)\n",
    "    # Two types of spikes are typicalled observed (check visualizaion by runnung  vizualization.ipnyb) \n",
    "    # one in positive direction and othes in negetive direction, so for robostness both are considered. \n",
    "    # At the same time, it is not wise to remove the original expected trajectory of the tool path in begining and the end,\n",
    "    # so especially for the positive direction they are intentionally not removed \n",
    "    print(-(np.mean(Y_final)-7*np.std(Y_final)), np.mean(Y_final), np.std(Y_final),(np.mean(Y_final)+7*np.std(Y_final)))\n",
    "    peaks1, _ = find_peaks(-Y_final, height=(-(np.mean(Y_final)-7*np.std(Y_final)),None))\n",
    "    #peaks2,_ = find_peaks(Y_final[0:-1000], height=(240,None))\n",
    "    peaks2,_ = find_peaks(Y_final, height=((np.mean(Y_final)+7*np.std(Y_final)),None))\n",
    "    peaks = list(peaks1) + list(peaks2)\n",
    "    print(peaks)\n",
    "    \n",
    "    if(len(peaks)==0):\n",
    "        break\n",
    "        \n",
    "    # if each peak on a plateu has to be removed its very expensive, so if two neighbous are consicutively classifies as peaks \n",
    "    # (given by count), it is assumed as plateu and 100 datapoints are removed.\n",
    "    # This is a reasonable compromise in accuracy for significant speedup\n",
    "        \n",
    "    #elif(len(peaks)==1 and abs(Y_final[peaks[0]] - Y_final[peaks[0]+20] )<=0.3):\n",
    "    elif(len(peaks)==1 and count>2 and peaks[-1]+100<final_df.shape[0]):\n",
    "        arr = final_df.to_numpy()\n",
    "        arr = np.delete(arr, np.arange(peaks[0],peaks[0]+100), 0)\n",
    "        final_df = pd.DataFrame(arr,columns=col)\n",
    "        count = 0\n",
    "        \n",
    "    elif(len(peaks)==1 and count>2 and (final_df.shape[0]-100<peaks[-1]<final_df.shape[0])):\n",
    "        arr = final_df.to_numpy()\n",
    "        arr = np.delete(arr, np.arange(peaks[0],peaks[0]+(final_df.shape[0]-peaks[-1])), 0)\n",
    "        final_df = pd.DataFrame(arr,columns=col)\n",
    "        count = 0\n",
    "        \n",
    "    else:\n",
    "        arr = final_df.to_numpy()\n",
    "        arr = np.delete(arr,peaks, 0)\n",
    "        final_df = pd.DataFrame(arr,columns=col)\n",
    "        count = count+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulaiztion of effect of removing peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = final_df['MachineX'].copy(deep=True)                 # using machine data from newly created combined dataset\n",
    "y_final = final_df['MachineY'].copy(deep=True)\n",
    "z_final = final_df['MachineZ'].copy(deep=True)\n",
    "a_final = final_df['MachineA'].copy(deep=True)\n",
    "c_final = final_df['MachineC'].copy(deep=True)\n",
    "\n",
    "size1_final = x_final.shape[0]\n",
    "print(size1_final)\n",
    "\n",
    "# converting pandas series to numpy array\n",
    "x_final = x_final.to_numpy()\n",
    "y_final = y_final.to_numpy()\n",
    "z_final = z_final.to_numpy()\n",
    "a_final = a_final.to_numpy(dtype =  np.float64)\n",
    "a_final = np.deg2rad(a_final)\n",
    "c_final = c_final.to_numpy(dtype =  np.float64)\n",
    "c_final = np.deg2rad(c_final)\n",
    "\n",
    "tool_tip_X_final = final_df['Tool Tip Point X'].to_numpy()        # using newly created combined dataset\n",
    "tool_tip_Y_final = final_df['Tool Tip Point Y'].to_numpy()\n",
    "tool_tip_Z_final = final_df['Tool Tip Point Z'].to_numpy()\n",
    "    \n",
    "X_inv_final = tool_tip_X_final\n",
    "Y_inv_final = tool_tip_Y_final\n",
    "Z_inv_final = tool_tip_Z_final\n",
    "    \n",
    "#compensation_values\n",
    "compensation_values = compensation_values_df.to_numpy()\n",
    "\n",
    "# Within each cube we have ranges defined in x,y,z for the machine position\n",
    "\n",
    "x_range = np.arange(-200,201,100)\n",
    "y_range = np.arange(-300,301,150)\n",
    "z_range = np.arange(-500,1,50)\n",
    "\n",
    "obj3_final = compensation.Compensation(compensation_values,x_range,y_range,z_range)\n",
    "\n",
    "# Caclculation of compensation error values based on machine positions obtained through inverse transformation\n",
    "deltaX1_final, deltaY1_final, deltaZ1_final,deltaI1_final,deltaJ1_final,deltaK1_final = obj3_final.calculate(x_final,y_final,z_final)  \n",
    "size3_final = x_final.shape[0]\n",
    "conc3_final = np.concatenate((deltaX1_final.reshape(size3_final,1),deltaY1_final.reshape(size3_final,1),deltaZ1_final.reshape(size3_final,1),deltaI1_final.reshape(size3_final,1),deltaJ1_final.reshape(size3_final,1),deltaK1_final.reshape(size3_final,1)),axis=1)\n",
    "\n",
    "# prininting the compensation error values\n",
    "df_obj3_final = pd.DataFrame(conc3_final, columns=['deltaX1 final','deltaY1 final','deltaZ1 final','deltaI1 final','deltaJ1 final','deltaK1 final'])\n",
    "df_obj3_final.head(5)  \n",
    "\n",
    "x_compensated_final = x_final + deltaX1_final*10**-3    # since given compensation is to be converted from microns to mm (10**-6 x 10**3 = 10**-3)\n",
    "y_compensated_final = y_final + deltaY1_final*10**-3\n",
    "z_compensated_final = z_final + deltaZ1_final*10**-3\n",
    "\n",
    "conc4_final = np.concatenate((x_compensated_final.reshape(size3_final,1),y_compensated_final.reshape(size3_final,1),z_compensated_final.reshape(size3_final,1)),axis=1)\n",
    "df_obj4_final = pd.DataFrame(conc4_final, columns=['x_compensated final','y_compensated final','z_compensated final'])\n",
    "\n",
    "obj_final = transformation.Transformation(size1_final,angle)\n",
    "# Forward Transformation fuction:\n",
    "# Input : Machine points in machine coordinate system\n",
    "# Output: returns too tip points and orientation in workpiece coordinate system\n",
    "tool_position_workpiece_CS_final, tool_orientation_workpiece_CS_final = obj_final.forward(x_compensated_final,y_compensated_final,z_compensated_final,a_final,c_final)\n",
    "\n",
    "X_final = tool_position_workpiece_CS_final[0,0,:]\n",
    "Y_final = tool_position_workpiece_CS_final[1,0,:]\n",
    "\n",
    "Z_final = tool_position_workpiece_CS_final[2,0,:]\n",
    "\n",
    "I_final = tool_orientation_workpiece_CS_final[0,0,:]\n",
    "J_final = tool_orientation_workpiece_CS_final[1,0,:]\n",
    "K_final = tool_orientation_workpiece_CS_final[2,0,:]\n",
    "\n",
    "# Verification the correctness of code, i.e on applying reverse transformation on the forward transformation we should get same values\n",
    "machine_points_xyz_final, machine_direction_ac_final = obj_final.backward(X_final,Y_final,Z_final,I_final,J_final,K_final)\n",
    "\n",
    "x_out_final = machine_points_xyz_final[0,0,:]\n",
    "y_out_final = machine_points_xyz_final[1,0,:]\n",
    "z_out_final = machine_points_xyz_final[2,0,:]\n",
    "\n",
    "a_out_final = machine_direction_ac_final[0,0,:]\n",
    "c_out_final = machine_direction_ac_final[1,0,:]\n",
    "\n",
    "conc1_final = np.concatenate((x_final.reshape(size1_final,1),x_out_final.reshape(size1_final,1),y_final.reshape(size1_final,1),y_out_final.reshape(size1_final,1),z_final.reshape(size1_final,1),z_out_final.reshape(size1_final,1),a_final.reshape(size1_final,1),a_out_final.reshape(size1_final,1),c_final.reshape(size1_final,1),c_out_final.reshape(size1_final,1)),axis=1)\n",
    "df_obj1_final = pd.DataFrame(conc1_final, columns=['x final','x_out final','y final','y_out final','z final','z_out final','a final','a_out final','c final','c_out'])\n",
    "\n",
    "conc11_final = np.concatenate((x_final.reshape(size1_final,1),y_final.reshape(size1_final,1),z_final.reshape(size1_final,1),a_final.reshape(size1_final,1),c_final.reshape(size1_final,1),X_final.reshape(size1_final,1),Y_final.reshape(size1_final,1),Z_final.reshape(size1_final,1),I_final.reshape(size1_final,1),J_final.reshape(size1_final,1),K_final.reshape(size1_final,1)),axis=1)\n",
    "dfout11_final = pd.DataFrame(conc11_final, columns=['x final','y final','z final','a final','c final','X final','Y final','Z final','I final','J final','K final'])\n",
    "    \n",
    "subplotter(0,final_df.shape[0],X_final,Y_final,Z_final,X_inv_final,Y_inv_final,Z_inv_final)   # using combined dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "div = 20\n",
    "length = Y_final.shape[0]\n",
    "chunk_len = int(length/div)\n",
    "    \n",
    "for i in np.arange(0,div):\n",
    "    if(i != div-1):\n",
    "        diff = Y_final[i*chunk_len:(i+1)*chunk_len] - Y_inv_final[i*chunk_len:(i+1)*chunk_len]\n",
    "        Y_final[i*chunk_len:(i+1)*chunk_len] = Y_final[i*chunk_len:(i+1)*chunk_len] - np.mean(diff)\n",
    "\n",
    "    else:\n",
    "        diff = Y_final[i*chunk_len:length] - Y_inv_final[i*chunk_len:length]\n",
    "        Y_final[i*chunk_len:length] = Y_final[i*chunk_len:length] - np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplotter(0,1000,X_final,Y_final,Z_final,X_inv_final,Y_inv_final,Z_inv_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(final_df, compensation_values_df):\n",
    "    x_final = final_df['MachineX']                 # using machine data from newly created combined dataset\n",
    "    y_final = final_df['MachineY']\n",
    "    z_final = final_df['MachineZ']\n",
    "    a_final = final_df['MachineA']\n",
    "    c_final = final_df['MachineC']\n",
    "\n",
    "    size1_final = x_final.shape[0]\n",
    "\n",
    "    # converting pandas series to numpy array\n",
    "    x_final = x_final.to_numpy()\n",
    "    y_final = y_final.to_numpy()\n",
    "    z_final = z_final.to_numpy()\n",
    "    a_final = a_final.to_numpy(dtype =  np.float64)\n",
    "    a_final = np.deg2rad(a_final)\n",
    "    c_final = c_final.to_numpy(dtype =  np.float64)\n",
    "    c_final = np.deg2rad(c_final)\n",
    "\n",
    "    tool_tip_X_final = final_df['Tool Tip Point X'].to_numpy()        # using newly created combined dataset\n",
    "    tool_tip_Y_final = final_df['Tool Tip Point Y'].to_numpy()\n",
    "    tool_tip_Z_final = final_df['Tool Tip Point Z'].to_numpy()\n",
    "\n",
    "    X_inv_final = tool_tip_X_final\n",
    "    Y_inv_final = tool_tip_Y_final\n",
    "    Z_inv_final = tool_tip_Z_final\n",
    "\n",
    "    #compensation_values\n",
    "    compensation_values = compensation_values_df.to_numpy()\n",
    "\n",
    "    # Within each cube we have ranges defined in x,y,z for the machine position\n",
    "\n",
    "    x_range = np.arange(-200,201,100)\n",
    "    y_range = np.arange(-300,301,150)\n",
    "    z_range = np.arange(-500,1,50)\n",
    "\n",
    "    obj3_final = compensation.Compensation(compensation_values,x_range,y_range,z_range)\n",
    "\n",
    "    # Caclculation of compensation error values based on machine positions obtained through inverse transformation\n",
    "    deltaX1_final, deltaY1_final, deltaZ1_final,deltaI1_final,deltaJ1_final,deltaK1_final = obj3_final.calculate(x_final,y_final,z_final)  \n",
    "\n",
    "    x_compensated_final = x_final + deltaX1_final*10**-3    # since given compensation is to be converted from microns to mm (10**-6 x 10**3 = 10**-3)\n",
    "    y_compensated_final = y_final + deltaY1_final*10**-3\n",
    "    z_compensated_final = z_final + deltaZ1_final*10**-3\n",
    "\n",
    "    obj_final = transformation.Transformation(size1_final,angle)\n",
    "    # Forward Transformation fuction:\n",
    "    # Input : Machine points in machine coordinate system\n",
    "    # Output: returns too tip points and orientation in workpiece coordinate system\n",
    "    tool_position_workpiece_CS_final, tool_orientation_workpiece_CS_final = obj_final.forward(x_compensated_final,y_compensated_final,z_compensated_final,a_final,c_final)\n",
    "\n",
    "    X_final = tool_position_workpiece_CS_final[0,0,:]\n",
    "    Y_final = tool_position_workpiece_CS_final[1,0,:]\n",
    "    Z_final = tool_position_workpiece_CS_final[2,0,:]\n",
    "\n",
    "    I_final = tool_orientation_workpiece_CS_final[0,0,:]\n",
    "    J_final = tool_orientation_workpiece_CS_final[1,0,:]\n",
    "    K_final = tool_orientation_workpiece_CS_final[2,0,:]\n",
    "\n",
    "    #Shifting the data \n",
    "    div = 20\n",
    "    length = Y_final.shape[0]\n",
    "    chunck_len = int(length/div)\n",
    "    \n",
    "    for i in np.arange(0,div):\n",
    "        if(i != div-1):\n",
    "            diff = Y_final[i*chunck_len:(i+1)*chunck_len] - Y_inv_final[i*chunck_len:(i+1)*chunck_len]\n",
    "            Y_final[i*chunck_len:(i+1)*chunck_len] = Y_final[i*chunck_len:(i+1)*chunck_len] - np.mean(diff)\n",
    "\n",
    "        else:\n",
    "            diff = Y_final[i*chunck_len:length] - Y_inv_final[i*chunck_len:length]\n",
    "            Y_final[i*chunck_len:length] = Y_final[i*chunck_len:length] - np.mean(diff)\n",
    "\n",
    "        \n",
    "    return X_final,Y_final,Z_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mc, Y_mc, Z_mc = shift(final_df,compensation_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Tool Tip Point Machine X'] = X_mc\n",
    "final_df['Tool Tip Point Machine Y'] = Y_mc\n",
    "final_df['Tool Tip Point Machine Z'] = Z_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.shape)\n",
    "final_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplotter(19000,final_df.shape[0],final_df['Tool Tip Point Machine X'],final_df['Tool Tip Point Machine Y'],final_df['Tool Tip Point Machine Z'],final_df['Tool Tip Point X'],final_df['Tool Tip Point Y'],final_df['Tool Tip Point Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tool point deviation\n",
    "\n",
    "tool_point_deviation = np.sqrt(((final_df['Tool Tip Point Machine X'] - final_df['Tool Tip Point X'])**2 + (final_df['Tool Tip Point Machine Y'] - final_df['Tool Tip Point Y'])**2 + (final_df['Tool Tip Point Machine Z'] - final_df['Tool Tip Point Z'])**2).to_numpy(dtype=np.float64))\n",
    "print(np.mean(tool_point_deviation))\n",
    "plt.hist(tool_point_deviation, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Tool Point Deviation'] = tool_point_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.iloc[10000:10020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot((final_df['tcp_error']).iloc[1000:3500])\n",
    "plt.title('TCP Error plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "ax1 = plt.axes(projection='3d')\n",
    "ax1.set_zlim3d([0,30])\n",
    "\n",
    "ax1.set_xlabel('$X$ in mm', fontsize=20)\n",
    "ax1.set_ylabel('$Y$ in mm', fontsize=20)\n",
    "ax1.set_zlabel('$Z$ in mm', fontsize=20)\n",
    "\n",
    "ax1.scatter3D(X_inv_final, Y_inv_final, Z_inv_final, color = 'red',label = 'Planning Data')\n",
    "ax1.legend()\n",
    "\n",
    "ax1.scatter3D(X_final, Y_final, Z_final, color = 'blue',label = 'Machine Data Avg')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = final_df['tcp_error'].mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = final_df['tcp_error'].median()\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "minimum = final_df['tcp_error'].min()\n",
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = final_df['tcp_error'].max()  \n",
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.iloc[0:21500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data \n",
    "final_df.to_excel(str(dir_final_save)+'finaldf_forward_with_compensation'+str(block)+'__'+str(angle)+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
